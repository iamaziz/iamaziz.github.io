
<!DOCTYPE HTML>
<html lang="en-GB">
<head>
	<meta charset="utf-8">
	<title>word2vec with NLTK retrain and evaluate  | Blogy</title>

	<meta name="author" content="Aziz Alto">

<meta name="description" content="<!-- [Word2vec](word2vec.googlecode.com) is a word-embedding algorithm, where words are represented as numerical vectors.
It attempts to understand &hellip;"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="Blogy" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	

</head>



<body>
	<header id="header" class="inner"><h1><a href="/">Blogy</a></h1>
<span class="tagline">Anything goes in mind</span>
<!-- <nav id="main-nav"><ul>
	<li><a href="/about">About</a></li>
	<li><a href="/archives">Archives</a></li>
	<li><a href="/contact">Contact</a></li>
</ul>

<ul>
  <li><a href="/about">About</a></li>
  <li><a href="/archives">Archive</a></li>
  <li><a href="/quotes">Quotes</a></li>
</ul>
</nav> -->
<!-- <nav id="mobile-nav"> -->
<!-- 	<div class="alignleft menu"> -->
<!-- 		<a class="button">Menu</a> -->
<!-- 		<div class="container"><ul>
	<li><a href="/about">About</a></li>
	<li><a href="/archives">Archives</a></li>
	<li><a href="/contact">Contact</a></li>
</ul>

<ul>
  <li><a href="/about">About</a></li>
  <li><a href="/archives">Archive</a></li>
  <li><a href="/quotes">Quotes</a></li>
</ul>
</div> -->
<!-- 	</div> -->
<!-- </nav> -->


</header>

	<div id="content" class="inner"><article class="post">
	<header>
		<h2 class="title">Word2vec With NLTK Retrain and Evaluate</h2>
		<div class="meta date">








  


<time datetime="2015-11-02T10:26:34-05:00" pubdate data-updated="true">Nov 2<sup>nd</sup>, 2015</time></div>
	</header>
	<div class="entry-content"><!-- [Word2vec](word2vec.googlecode.com) is a word-embedding algorithm, where words are represented as numerical vectors.
It attempts to understand meaning and semantics relationships among words. -->
<p>I came across the interesting post <a href="http://streamhacker.com/2014/12/29/word2vec-nltk/">Using Word2vec with NLTK</a>. It demonstrates how <a href="https://code.google.com/p/word2vec/">word2vec</a> may represent the semantic of the same word differently depending on the textual context of your dataset. Take a look at the post, then come back here.</p>

<p>I wonder how the <strong>semantic similarities</strong> and <strong>accuracy</strong> (of word2vec model) would change after re-training the same model on both datasets, <code>brown</code> and <code>movie_reviews</code>. After experimenting on that, here is what I got.</p>

<p>Train and test:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">brown</span><span class="p">,</span> <span class="n">movie_reviews</span><span class="p">,</span> <span class="n">treebank</span>
</span><span class="line">
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># training a model on brown dataset</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">brown</span><span class="o">.</span><span class="n">sents</span><span class="p">())</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># RESULTS</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s">&#39;money&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span><span class="line"><span class="p">[(</span><span class="s">u&#39;pay&#39;</span><span class="p">,</span> <span class="mf">0.6832360029220581</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;ready&#39;</span><span class="p">,</span> <span class="mf">0.6151966452598572</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;try&#39;</span><span class="p">,</span> <span class="mf">0.584543764591217</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;care&#39;</span><span class="p">,</span> <span class="mf">0.582566499710083</span><span class="p">)]</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># ACCURACY</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">w2v_model_accuracy</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span class="line"> <span class="n">Total</span><span class="p">:</span> <span class="mi">5086</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">19544</span><span class="p">,</span> <span class="n">Correct</span><span class="p">:</span> <span class="mf">1.63</span><span class="o">%</span><span class="p">,</span> <span class="n">Incorrect</span><span class="p">:</span> <span class="mf">98.37</span><span class="o">%</span>
</span><span class="line">
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># training a model on movie_reviews</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">mr</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">movie_reviews</span><span class="o">.</span><span class="n">sents</span><span class="p">())</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># RESULTS</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">mr</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s">&#39;money&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span><span class="line"><span class="p">[(</span><span class="s">u&#39;unstoppable&#39;</span><span class="p">,</span> <span class="mf">0.6963834762573242</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;pain&#39;</span><span class="p">,</span> <span class="mf">0.6333830952644348</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;patients&#39;</span><span class="p">,</span> <span class="mf">0.6195155382156372</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;jail&#39;</span><span class="p">,</span> <span class="mf">0.6182809472084045</span><span class="p">)]</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># ACCURACY</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">w2v_model_accuracy</span><span class="p">(</span><span class="n">mr</span><span class="p">)</span>
</span><span class="line"><span class="n">Total</span><span class="p">:</span> <span class="mi">5613</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">19544</span><span class="p">,</span> <span class="n">Correct</span><span class="p">:</span> <span class="mf">2.73</span><span class="o">%</span><span class="p">,</span> <span class="n">Incorrect</span><span class="p">:</span> <span class="mf">97.27</span><span class="o">%</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now, lets look at the results after re-training both models on each otherâ€™s dataset:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># retrain brown model with movie_reviews sentences</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">movie_reviews</span><span class="o">.</span><span class="n">sents</span><span class="p">())</span>
</span><span class="line"><span class="mi">1352672</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s">&#39;money&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span><span class="line"><span class="p">[(</span><span class="s">u&#39;cash&#39;</span><span class="p">,</span> <span class="mf">0.7034180164337158</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;plans&#39;</span><span class="p">,</span> <span class="mf">0.6980791687965393</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;attention&#39;</span><span class="p">,</span> <span class="mf">0.6741234660148621</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;pay&#39;</span><span class="p">,</span> <span class="mf">0.6686939597129822</span><span class="p">)]</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">w2v_model_accuracy</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span class="line"><span class="n">Total</span><span class="p">:</span> <span class="mi">5086</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">19544</span><span class="p">,</span> <span class="n">Correct</span><span class="p">:</span> <span class="mf">4.25</span><span class="o">%</span><span class="p">,</span> <span class="n">Incorrect</span><span class="p">:</span> <span class="mf">95.75</span><span class="o">%</span>
</span><span class="line">
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="c"># retrain movie_reviews model with brown sentences</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">mr</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">brown</span><span class="o">.</span><span class="n">sents</span><span class="p">())</span>
</span><span class="line"><span class="mi">946806</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">mr</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s">&#39;money&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span><span class="line"><span class="p">[(</span><span class="s">u&#39;trouble&#39;</span><span class="p">,</span> <span class="mf">0.6961323022842407</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;worries&#39;</span><span class="p">,</span> <span class="mf">0.6873552799224854</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;stay&#39;</span><span class="p">,</span> <span class="mf">0.6835054159164429</span><span class="p">),</span>
</span><span class="line"> <span class="p">(</span><span class="s">u&#39;comfort&#39;</span><span class="p">,</span> <span class="mf">0.6833420991897583</span><span class="p">)]</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">w2v_model_accuracy</span><span class="p">(</span><span class="n">mr</span><span class="p">)</span>
</span><span class="line"><span class="n">Total</span><span class="p">:</span> <span class="mi">5613</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">19544</span><span class="p">,</span> <span class="n">Correct</span><span class="p">:</span> <span class="mf">5.18</span><span class="o">%</span><span class="p">,</span> <span class="n">Incorrect</span><span class="p">:</span> <span class="mf">94.82</span><span class="o">%</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>As expected, the accuracy of both models increased after re-training (notic: training again on the same dataset will decrease accuracy).</p>

<p>Interesting thing is that, after the re-trainging, the results are still different although both models are technically trained on the same datasets. This may suggest that the order in which you feed your model more data does matter.</p>

<p>Here is the evaluation function, I used:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c">### compute accuracy</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">w2v_model_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="c"># https://word2vec.googlecode.com/svn/trunk/questions-words.txt</span>
</span><span class="line">    <span class="n">questions</span> <span class="o">=</span> <span class="s">&#39;questions-words.txt&#39;</span>
</span><span class="line">    <span class="n">evals</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="s">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
</span><span class="line">    <span class="n">num_sections</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">evals</span> <span class="k">if</span> <span class="n">l</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&#39;:&#39;</span><span class="p">)])</span>
</span><span class="line">    <span class="n">num_sents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_sections</span>
</span><span class="line">
</span><span class="line">    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">sum_corr</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">accuracy</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s">&#39;correct&#39;</span><span class="p">])</span>
</span><span class="line">    <span class="n">sum_incorr</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">accuracy</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s">&#39;incorrect&#39;</span><span class="p">])</span>
</span><span class="line">    <span class="n">total</span> <span class="o">=</span> <span class="n">sum_corr</span> <span class="o">+</span> <span class="n">sum_incorr</span>
</span><span class="line">    <span class="n">percent</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="mi">100</span>
</span><span class="line">    <span class="k">print</span><span class="p">(</span><span class="s">&#39;Total: {} out of {}, Correct: {:.2f}%, Incorrect: {:.2f}%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total</span><span class="p">,</span> <span class="n">num_sents</span><span class="p">,</span> <span class="n">percent</span><span class="p">(</span><span class="n">sum_corr</span><span class="p">),</span> <span class="n">percent</span><span class="p">(</span><span class="n">sum_incorr</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
</div>

</article>

	
	<div class="share">
	  <!-- <ul> -->
	  <!--   <li>
  <a href="https://twitter.com/intent/tweet?text=word2vec with NLTK retrain and evaluate by @AzizAlto&url=http://iamaziz.github.io/blog/2015/11/02/word2vec-with-nltk-retrain-and-evaluate/" title="Share word2vec with NLTK retrain and evaluate on Twitter">
    <img src="/images/social/twitter.png" />
  </a>
</li>
 -->
	  <!--   <li>
  <a href="https://www.facebook.com/sharer.php?u=http://iamaziz.github.io/blog/2015/11/02/word2vec-with-nltk-retrain-and-evaluate/" title="Share word2vec with NLTK retrain and evaluate on Facebook">
    <img src="/images/social/facebook.png" />
  </a>
</li>
 -->
	  <!--   <li>
  <a href="https://plus.google.com/share?url=http://iamaziz.github.io/blog/2015/11/02/word2vec-with-nltk-retrain-and-evaluate/" title="Share word2vec with NLTK retrain and evaluate on Google Plus">
    <img src="/images/social/google.png" />
  </a>
</li>
 -->
	  <!-- </ul> -->
	</div>




<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>
</div>
	<footer id="footer" class="inner"><br>
<br>
<br>
<br>
&copy; 2015

    Aziz Alto
    <br>
    Powered by <a href="http://octopress.org/">Octopress</a>


</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/hyphenator.js"></script>


<script type="text/javascript">
      var disqus_shortname = 'iamaziz';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://iamaziz.github.io/blog/2015/11/02/word2vec-with-nltk-retrain-and-evaluate/';
        var disqus_url = 'http://iamaziz.github.io/blog/2015/11/02/word2vec-with-nltk-retrain-and-evaluate/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-52965376-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>




</body>
<script>
  $(document).ready(function() {
  // Make images center
  $('p:has(img)').css('text-align', 'center');
  });
</script>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

</html>
